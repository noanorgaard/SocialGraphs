{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4557bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# number of playlist to process out of the slice files\n",
    "NUM_PLAYLISTS = 1000\n",
    "\n",
    "# Path to your original slice file\n",
    "folder_path = Path(r\"/Users/noa/Desktop/02805 - Social Graphs/playlist_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc0a645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 files, total playlists merged: 6000\n",
      "Total playlists in this slice: 6000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load all mpd slice JSON files in the folder and merge their playlists\n",
    "file_list = sorted(folder_path.glob(\"mpd.slice.*.json\"))\n",
    "playlists = []\n",
    "for fp in file_list:\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        playlists.extend(data.get(\"playlists\", []))\n",
    "\n",
    "mpd_slice = {\n",
    "    \"info\": {\"merged_from_files\": len(file_list)},\n",
    "    \"playlists\": playlists\n",
    "}\n",
    "\n",
    "print(f\"Loaded {len(file_list)} files, total playlists merged: {len(mpd_slice['playlists'])}\")\n",
    "\n",
    "# Check how many playlists are inside\n",
    "print(f\"Total playlists in this slice: {len(mpd_slice['playlists'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21132e77",
   "metadata": {},
   "source": [
    "Make a network going through 6000 playlists (mpd_slice)\n",
    "\n",
    "Nodes are artists occuring in the songs of the networks\n",
    "\n",
    "Add song titles from playlists to the nodes, disregarding duplicates.\n",
    "\n",
    "add playlist id as attribute to artist if they have a song on playlist\n",
    "\n",
    "Edges are between artists if they share a playlist\n",
    "\n",
    "weight on edge is the number of playlist they share\n",
    "\n",
    "dont include playlist having less then 40 songs and more then 100\n",
    "\n",
    "dont include playlists having less than 6 unique artists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ccc903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building artist network from 1000 playlists\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Build network from the mpd_slice playlists (up to first 100 playlists in the slice)\n",
    "playlists = mpd_slice.get(\"playlists\", [])[:NUM_PLAYLISTS]\n",
    "print(f\"\\nBuilding artist network from {len(playlists)} playlists\")\n",
    "\n",
    "# Accumulators (dictionaries of sets)\n",
    "artist_songs = defaultdict(set)        # artist -> set of song titles\n",
    "artist_playlists = defaultdict(set)    # artist -> set of playlist ids they appear in\n",
    "edge_playlists = defaultdict(set)      # (artist_a, artist_b) -> set of playlist ids they share\n",
    "\n",
    "included_playlists = 0\n",
    "\n",
    "for pl in playlists:\n",
    "    pid = pl.get(\"pid\")\n",
    "    tracks = pl.get(\"tracks\", [])\n",
    "    # filter playlists by track count and unique artist count\n",
    "    if not (40 <= len(tracks) <= 100):\n",
    "        continue\n",
    "    unique_artists = {t[\"artist_name\"] for t in tracks}\n",
    "    if len(unique_artists) < 6:\n",
    "        continue\n",
    "\n",
    "    included_playlists += 1\n",
    "\n",
    "    # collect songs and playlist membership per artist\n",
    "    for t in tracks:\n",
    "        artist = t[\"artist_name\"]\n",
    "        track_name = t.get(\"track_name\")\n",
    "        if track_name:\n",
    "            artist_songs[artist].add(track_name)\n",
    "        artist_playlists[artist].add(pid)\n",
    "\n",
    "    # increment edge counters for every pair of artists in this playlist\n",
    "    for a, b in combinations(sorted(unique_artists), 2):\n",
    "        edge_playlists[(a, b)].add(pid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d22831",
   "metadata": {},
   "source": [
    "Steps to Implement:\n",
    "\n",
    "- Filter playlists: If any song in a playlist cannot be found on Genius, discard the entire playlist.\n",
    "- Fetch lyrics: Use the Genius API to get lyrics for each unique song per artist.\n",
    "- Concatenate lyrics per artist: Combine lyrics for all unique songs by that artist into one text block.\n",
    "- Save to .txt files: Store each artistâ€™s lyrics in a separate file so you can load them later without re-scraping.\n",
    "- Attach lyrics as an attribute in the graph: When building the NetworkX graph, add the lyrics as a node attribute.\n",
    "\n",
    "Considerations\n",
    "- Avoid duplicates: Only fetch lyrics for unique songs per artist.\n",
    "- Rate limits: Genius API has limits, so you may need to add delays or caching.\n",
    "- Error handling: If any song in a playlist fails, skip that playlist entirely.\n",
    "- File structure: Use a folder like artist_lyrics/ to store .txt files named after the artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69694e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- SETUP GENIUS API ---\n",
    "GENIUS_ACCESS_TOKEN = \"IKoqZN1ANyU_2G6zmTPF2xlaH2OlIEEUlDoD97Mo9-P_A6-2QgnSoQlwsJ3Hy3DY\"  # <--- paste your token\n",
    "\n",
    "# Initialize Genius client\n",
    "genius = lyricsgenius.Genius(\n",
    "    GENIUS_ACCESS_TOKEN,\n",
    "    remove_section_headers=True,   # cleans up [Verse], etc.\n",
    "    timeout=15,\n",
    "    retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969816de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Get Ur Freak On\" by Missy Elliott...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m track_name \u001b[38;5;129;01min\u001b[39;00m songs:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         song = genius.search_song(track_name, artist)\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m song \u001b[38;5;129;01mand\u001b[39;00m song.lyrics:\n\u001b[32m     15\u001b[39m             artist_lyrics[artist] += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + song.lyrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/lyricsgenius/genius.py:522\u001b[39m, in \u001b[36mGenius.search_song\u001b[39m\u001b[34m(self, title, artist, song_id, get_full_info)\u001b[39m\n\u001b[32m    517\u001b[39m     song_info.update(\u001b[38;5;28mself\u001b[39m.song(song_info[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m])[\u001b[33m\"\u001b[39m\u001b[33msong\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m song_info[\u001b[33m\"\u001b[39m\u001b[33mlyrics_state\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mcomplete\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m song_info.get(\n\u001b[32m    520\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minstrumental\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    521\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     lyrics = \u001b[38;5;28mself\u001b[39m.lyrics(song_url=song_info[\u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    524\u001b[39m     lyrics = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/lyricsgenius/genius.py:167\u001b[39m, in \u001b[36mGenius.lyrics\u001b[39m\u001b[34m(self, song_id, song_url, remove_section_headers)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou must supply either `song_id` or `song_url`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Scrape the song lyrics from the HTML\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m soup = BeautifulSoup(\u001b[38;5;28mself\u001b[39m._make_request(path, web=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[33m\"\u001b[39m\u001b[33mhtml\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Remove LyricsHeader divs from the DOM\u001b[39;00m\n\u001b[32m    170\u001b[39m removes = soup.find_all(\u001b[33m\"\u001b[39m\u001b[33mdiv\u001b[39m\u001b[33m\"\u001b[39m, class_=re.compile(\u001b[33m\"\u001b[39m\u001b[33mLyricsHeader\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/lyricsgenius/api/base.py:88\u001b[39m, in \u001b[36mSender._make_request\u001b[39m\u001b[34m(self, path, method, params_, public_api, web, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m tries += \u001b[32m1\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._session.request(\n\u001b[32m     89\u001b[39m         method,\n\u001b[32m     90\u001b[39m         uri,\n\u001b[32m     91\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout,\n\u001b[32m     92\u001b[39m         params=params_,\n\u001b[32m     93\u001b[39m         headers=header,\n\u001b[32m     94\u001b[39m         **kwargs,\n\u001b[32m     95\u001b[39m     )\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Timeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m     error = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequest timed out:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28mself\u001b[39m.send(prep, **send_kwargs)\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/requests/sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     r.content\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/requests/models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m.iter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/urllib3/response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/urllib3/response.py:1251\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m chunk = \u001b[38;5;28mself\u001b[39m._handle_chunk(amt)\n\u001b[32m   1252\u001b[39m decoded = \u001b[38;5;28mself\u001b[39m._decode(\n\u001b[32m   1253\u001b[39m     chunk, decode_content=decode_content, flush_decoder=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1254\u001b[39m )\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/site-packages/urllib3/response.py:1188\u001b[39m, in \u001b[36mHTTPResponse._handle_chunk\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28mself\u001b[39m.chunk_left = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt < \u001b[38;5;28mself\u001b[39m.chunk_left:\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._fp._safe_read(amt)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28mself\u001b[39m.chunk_left = \u001b[38;5;28mself\u001b[39m.chunk_left - amt\n\u001b[32m   1190\u001b[39m     returned_chunk = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/http/client.py:642\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    637\u001b[39m \n\u001b[32m    638\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.fp.read(amt)\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    644\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sock.recv_into(b)\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read(nbytes, buffer)\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/python_env_3_12/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Folder to save lyrics\n",
    "lyrics_folder = Path(\"artist_lyrics\")\n",
    "lyrics_folder.mkdir(exist_ok=True)\n",
    "\n",
    "artist_lyrics = defaultdict(str)\n",
    "\n",
    "for artist, songs in artist_songs.items():\n",
    "    for track_name in songs:\n",
    "        try:\n",
    "            song = genius.search_song(track_name, artist)\n",
    "            if song and song.lyrics:\n",
    "                artist_lyrics[artist] += \"\\n\" + song.lyrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving {track_name} by {artist}: {e}\")\n",
    "        time.sleep(1)  # Avoid hitting rate limits\n",
    "\n",
    "# Save lyrics to files\n",
    "for artist, lyrics in artist_lyrics.items():\n",
    "    safe_name = re.sub(r'[^\\w\\s-]', '', artist).strip().replace(' ', '_')\n",
    "    file_path = lyrics_folder / f\"{safe_name}.txt\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(lyrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
